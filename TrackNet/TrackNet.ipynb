{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrackNet Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import queue\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from turbojpeg import TurboJPEG\n",
    "from PIL import Image,ImageDraw\n",
    "\n",
    "from scipy import ndimage, misc\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "print('Device: ' + str(device))\n",
    "if use_cuda:\n",
    "    print('GPU: ' + str(torch.cuda.get_device_name(0)))\n",
    "\n",
    "# Turns on cuDNN Autotuner\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrackNet Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "dataset_base_path = \"./Dataset\"\n",
    "savePath_base = \"./Trained_Models\"\n",
    "outputPath = \"./Results\"\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-4\n",
    "eps = 1e-7\n",
    "\n",
    "# TrackNet width and height\n",
    "TN_width=640\n",
    "TN_height=360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([\n",
    "  albumentations.Resize(height=TN_height, width=TN_width, interpolation=1, always_apply=True, p=1),\n",
    "])\n",
    "\n",
    "def getOutputArr(path,outClasses=256,w=TN_width,h=TN_height):\n",
    "  seg_labels = np.zeros((h, w, outClasses))\n",
    "  img = cv.imread(path, 1)\n",
    "  img = cv.resize(img, (w, h))\n",
    "  img = img[:, : , 0]\n",
    "  for c in range(outClasses):\n",
    "    seg_labels[:, :, c] = (img==c).astype(int)\n",
    "\n",
    "  seg_labels = np.reshape(seg_labels, (w*h, outClasses))\n",
    "  return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TN_Dataset(Dataset):\n",
    "  def __init__(self, split):\n",
    "    self.window_paths = []\n",
    "    self.mask_paths = []\n",
    "    self.jpeg_reader = TurboJPEG()\n",
    "    \n",
    "    game_list = os.listdir(f\"{dataset_base_path}/{split}\")\n",
    "    # Iterate through each game\n",
    "    for game in game_list:\n",
    "      if game == \"groundtruth\":\n",
    "        continue\n",
    "      if int(game) > 10:\n",
    "        continue\n",
    "      game_dir = f\"{dataset_base_path}/{split}/{game}\"\n",
    "      clips = os.listdir(game_dir)\n",
    "      for clip in clips:\n",
    "        # Read and store label information\n",
    "        clip_dir = f\"{game_dir}/{clip}\"\n",
    "        annotation_path = f\"{clip_dir}/Label.csv\"\n",
    "        label = pd.read_csv(annotation_path)\n",
    "        img_paths = np.asarray(label.iloc[:, 0])\n",
    "\n",
    "        for frame_no, frame in enumerate(img_paths):\n",
    "          # Skip frames not in this dataset\n",
    "          if frame_no == 0 or frame_no == len(img_paths) - 1:\n",
    "            continue\n",
    "          window_path = []\n",
    "          window_path.append(f\"{clip_dir}/{img_paths[frame_no-1]}\")\n",
    "          window_path.append(f\"{clip_dir}/{img_paths[frame_no]}\")\n",
    "          window_path.append(f\"{clip_dir}/{img_paths[frame_no+1]}\")\n",
    "          self.window_paths.append(window_path)\n",
    "\n",
    "          mask_path = f\"{dataset_base_path}/{split}/groundtruth/{game}/{clip}/{frame.split('.')[0]}.png\"\n",
    "          self.mask_paths.append(mask_path)\n",
    "\n",
    "  def loader(self, path):\n",
    "    in_file = open(path, 'rb')\n",
    "    image = self.jpeg_reader.decode(in_file.read(), 0)\n",
    "    image = transform(**{\"image\": image})\n",
    "    image = image['image']\n",
    "    return image\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_1 = self.loader(self.window_paths[index][0])\n",
    "    img_2 = self.loader(self.window_paths[index][1])\n",
    "    img_3 = self.loader(self.window_paths[index][2])\n",
    "    img_window = np.concatenate((img_1, img_2, img_3),axis=2)\n",
    "    img_window = np.rollaxis(img_window, 2, 0)\n",
    "    img_window = torch.from_numpy(img_window)\n",
    "    \n",
    "    label = getOutputArr(self.mask_paths[index])\n",
    "    centre_img = cv.imread(self.window_paths[index][1])\n",
    "    centre_img = cv.resize(centre_img, (TN_width, TN_height))\n",
    "    centre_img.astype(np.float32)\n",
    "    \n",
    "    return img_window, label, centre_img\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.window_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 2\n",
    "val_batch = 2\n",
    "test_batch = 1\n",
    "num_workers = 8\n",
    "\n",
    "print(\"Loading Train...\")\n",
    "train_loader = DataLoader(TN_Dataset(split=\"train\"), batch_size=train_batch,shuffle=True,num_workers=num_workers,pin_memory=True,drop_last=True)\n",
    "print(\"Loading Test...\")\n",
    "test_loader = DataLoader(TN_Dataset(split=\"test\"), batch_size=test_batch,shuffle=False,num_workers=num_workers)\n",
    "print(\"Loading Validation...\")\n",
    "val_loader = DataLoader(TN_Dataset(split=\"val\"), batch_size=val_batch,shuffle=False,num_workers=num_workers,pin_memory=True,drop_last=True)\n",
    "print(\"Dataset total batches:\")\n",
    "print(f\"Training : {len(train_loader)}\")\n",
    "print(f\"Validation : {len(val_loader)}\")\n",
    "print(f\"Test : {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock2(nn.Module):\n",
    "  def __init__(self,in_channels,out_channels):\n",
    "    super(ConvBlock2, self).__init__() \n",
    "    self.block = nn.Sequential(\n",
    "      nn.Conv2d(in_channels = in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),          \n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.Conv2d(in_channels = out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1), \n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "    )\n",
    "\n",
    "  def forward(self, x): \n",
    "    return self.block(x)\n",
    "\n",
    "class ConvBlock3(nn.Module):\n",
    "  def __init__(self,in_channels,out_channels):\n",
    "    super(ConvBlock3, self).__init__() \n",
    "    self.block = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1), \n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1), \n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "      nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),          \n",
    "      nn.ReLU(),\n",
    "      nn.BatchNorm2d(out_channels),\n",
    "    )\n",
    "\n",
    "  def forward(self, x): \n",
    "    return self.block(x)\n",
    "\n",
    "class TrackNet(nn.Module):\n",
    "  def __init__(self,inchannel=3):\n",
    "    super(TrackNet, self).__init__()\n",
    "    self.down_sample = nn.Sequential(\n",
    "      ConvBlock2(in_channels=inchannel, out_channels=64),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      ConvBlock2(in_channels=64, out_channels=128),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      ConvBlock3(in_channels=128, out_channels=256),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      ConvBlock3(in_channels=256, out_channels=512),\n",
    "    )\n",
    "\n",
    "    self.up_sample = nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2),\n",
    "        ConvBlock3(in_channels=512, out_channels=256),\n",
    "        nn.Upsample(scale_factor=2),\n",
    "        ConvBlock2(in_channels=256, out_channels=128),\n",
    "        nn.Upsample(scale_factor=2),\n",
    "        ConvBlock2(in_channels=128, out_channels=64),\n",
    "        nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(256),\n",
    "    )\n",
    "\n",
    "    self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    out = self.down_sample(x)\n",
    "    out = self.up_sample(out)\n",
    "    out_shape = out.shape\n",
    "    out = out.reshape((out_shape[0],-1,out_shape[2]*out_shape[3]))\n",
    "    out = out.permute(0,2,1)\n",
    "    out = self.softmax(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Model and optimizer ########\n",
    "model_saved = True\n",
    "model = TrackNet(inchannel=9).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "scaler = GradScaler()\n",
    "colors = [(i, i, i) for i in range(0, 256)]\n",
    "train_loss_log = []\n",
    "val_loss_log = []\n",
    "model.train()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_saved):\n",
    "  savePath = f\"{savePath_base}/New_loader/TrackNet_14.pth\"\n",
    "  print(\"Loading model from path: \")\n",
    "  print(savePath)\n",
    "  checkpoint = torch.load(savePath)\n",
    "  model.load_state_dict(checkpoint['model'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  start_epoch = checkpoint['epoch']\n",
    "  train_loss_log = checkpoint['train_loss_log']\n",
    "  val_loss_log = checkpoint['val_loss_log']\n",
    "  print(f\"Load epoch {start_epoch} successful\")\n",
    "else:\n",
    "  start_epoch = 0\n",
    "  print(\"No model to load, start training at epoch 0\")\n",
    "\n",
    "print('START TRAINING ...')\n",
    "for epoch in range(start_epoch+1, num_epochs + 1):\n",
    "  model.train()\n",
    "  batch_num = len(train_loader)\n",
    "  train_loss = 0\n",
    "  train_loss_total = 0\n",
    "\n",
    "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "    for data_batch in tepoch:\n",
    "      tepoch.set_description(f\"Train Epoch {epoch}\")\n",
    "      # Read in train batch\n",
    "      img_window, label, _ = data_batch\n",
    "      window_batch = torch.as_tensor(img_window, dtype=torch.float32).to(device)\n",
    "      label_tensor = torch.as_tensor(label, dtype=torch.float32).to(device)\n",
    "      \n",
    "      # Forward step and calculate loss\n",
    "      with autocast():\n",
    "        output = model(window_batch)\n",
    "        train_loss = -torch.sum(label_tensor.mul(torch.log(output+eps)))/(output.shape[0]*output.shape[1]*output.shape[2])\n",
    "\n",
    "      # Backward step\n",
    "      optimizer.zero_grad(set_to_none=True)\n",
    "      scaler.scale(train_loss).backward()\n",
    "      scaler.step(optimizer)\n",
    "      scaler.update()\n",
    "      loss = train_loss.detach().cpu().numpy()\n",
    "      train_loss_total += loss\n",
    "      tepoch.set_postfix(loss=loss)\n",
    "\n",
    "  # Log training losses\n",
    "  tqdm.write(f\"Train\\t epoch: {epoch}/{num_epochs}\\t loss: {train_loss_total/batch_num}\")\n",
    "  train_loss_log.append(train_loss_total/batch_num)\n",
    "\n",
    "  # Validation dataset\n",
    "  with torch.no_grad():   \n",
    "    model.eval()\n",
    "    batch_num = len(val_loader)\n",
    "    val_loss = 0\n",
    "    val_loss_total = 0\n",
    "\n",
    "    with tqdm(val_loader, unit=\"batch\") as vepoch:\n",
    "      for data_batch in vepoch:\n",
    "        vepoch.set_description(f\"Validation Epoch {epoch}\")\n",
    "        # Read in val batch\n",
    "        img_window, label, _ = data_batch\n",
    "        window_batch = torch.as_tensor(img_window, dtype=torch.float32).to(device)\n",
    "        label_tensor = torch.as_tensor(label, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Forward step and calculate loss\n",
    "        with autocast():\n",
    "          output = model(window_batch)\n",
    "          val_loss = -torch.sum(label_tensor.mul(torch.log(output+eps)))/(output.shape[0]*output.shape[1]*output.shape[2])\n",
    "        \n",
    "        loss = train_loss.detach().cpu().numpy()\n",
    "        val_loss_total += loss\n",
    "        vepoch.set_postfix(loss=loss)\n",
    "\n",
    "    # Log validation losses\n",
    "    tqdm.write(f\"Validation\\t epoch: {epoch}/{num_epochs}\\t loss: {val_loss_total/batch_num}\")\n",
    "    val_loss_log.append(val_loss_total/batch_num)\n",
    "\n",
    "  #Save model  \n",
    "  tqdm.write(\"Saving model\")\n",
    "  state = {'model':model.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch, 'train_loss_log':train_loss_log, 'val_loss_log':val_loss_log}\n",
    "  savePath = f\"{savePath_base}/New_loader/TrackNet_{epoch}.pth\"\n",
    "  torch.save(state, savePath)\n",
    "  model_saved = True\n",
    "\n",
    "  plt.clf()\n",
    "  plt.figure(dpi=300)\n",
    "  plt.plot(range(1, epoch+1),train_loss_log,label='Train loss')\n",
    "  plt.plot(range(1, epoch+1),val_loss_log,label='Validation loss')\n",
    "  plt.legend()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title('Training loss')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(data, m = 2.):\n",
    "  out = np.copy(data)\n",
    "  d = np.abs(data - np.median(data))\n",
    "  mdev = np.median(d)\n",
    "  s = d/mdev if mdev else 0.\n",
    "  outlier_ids = np.nonzero(s>m)\n",
    "  for id in outlier_ids:\n",
    "    out[id] = -1\n",
    "  return out\n",
    "\n",
    "def interp(data):\n",
    "  for row in range(data.shape[0]):\n",
    "    # Prevent end of array error\n",
    "    if row == data.shape[0]-1:\n",
    "      continue\n",
    "    if data[row+1] == -1:\n",
    "      shift = 1\n",
    "      end_of_data = False\n",
    "      while data[row+shift] == -1:\n",
    "        shift += 1\n",
    "        if row+shift == data.shape[0]:\n",
    "          end_of_data = True\n",
    "          break\n",
    "      \n",
    "      # Repeat last seen prediction if there isnt a prediction for last frames\n",
    "      change = 0 if end_of_data else data[row+shift] - data[row]\n",
    "\n",
    "      prev = data[row]\n",
    "      for i in range(1,shift):\n",
    "       data[row+i] = prev+change/shift\n",
    "       prev = data[row+i]\n",
    "  return data\n",
    "\n",
    "def smooth(x,window_len=11,window='hanning'):\n",
    "  s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "  if window == 'flat': #moving average\n",
    "      w=np.ones(window_len,'d')\n",
    "  else:\n",
    "      w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "  y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "  return y\n",
    "\n",
    "def refine_detections(data, repeats=2, window_len=11):\n",
    "\n",
    "  for i in range(repeats):\n",
    "    out = np.copy(data)\n",
    "    # Reject the outliers\n",
    "    rejection_sz = 30\n",
    "    for i in range(0, data.shape[0], rejection_sz//2):\n",
    "      slice = data[i:i+rejection_sz-1]\n",
    "      rejected = reject_outliers(slice)\n",
    "      out[i:i+rejection_sz-1] = rejected\n",
    "    \n",
    "    # Interpolate between rejections\n",
    "    data = interp(out)\n",
    "    data[:2] = data[3]\n",
    "    unsmooth = data\n",
    "\n",
    "  unfiltered = data\n",
    "  data = ndimage.median_filter(data, size=20)\n",
    "  data = savgol_filter(data, 51, 3)\n",
    "  minima = argrelextrema(data, np.less)[0]\n",
    "  maxima = argrelextrema(data, np.greater)[0]\n",
    "\n",
    "  return data, minima, maxima, unfiltered\n",
    "\n",
    "def clean_extrema(extrema):\n",
    "  out = []\n",
    "  i = 0\n",
    "  while i < len(extrema):\n",
    "    if i+1 == len(extrema):\n",
    "      i += 1\n",
    "      continue\n",
    "    cur = extrema[i]\n",
    "    next = extrema[i+1]\n",
    "    close = [cur]\n",
    "    while next - cur <= 10:\n",
    "      close.append(next)\n",
    "      i += 1\n",
    "      if i+1 >= len(extrema):\n",
    "        break\n",
    "      next = extrema[i+1]\n",
    "    i += 1\n",
    "    if len(close) == 1:\n",
    "      continue\n",
    "    out.append(close)\n",
    "\n",
    "  for sub in out:\n",
    "    avr = sum(sub) // len(sub)\n",
    "    id = extrema.index(sub[0])\n",
    "    for num in sub:\n",
    "      extrema.remove(num)\n",
    "    extrema.insert(id, avr)\n",
    "  return extrema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([\n",
    "  albumentations.Resize(height=TN_height, width=TN_width, interpolation=1, always_apply=True, p=1),\n",
    "])\n",
    "\n",
    "class DemoDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.window_size = 3\n",
    "    self.window_paths = []\n",
    "    self.jpeg_reader = TurboJPEG()\n",
    "    self.img_paths = sorted(glob.glob('./tmp/*.jpg'))\n",
    "    \n",
    "    for frame_no, _ in enumerate(self.img_paths):\n",
    "      if not (self.window_size-2 < frame_no <= len(self.img_paths)-2):\n",
    "        continue\n",
    "      \n",
    "      # Get frame window image paths\n",
    "      window_path = []\n",
    "      window_path.append(self.img_paths[frame_no-1])\n",
    "      window_path.append(self.img_paths[frame_no])\n",
    "      window_path.append(self.img_paths[frame_no+1])\n",
    "      self.window_paths.append(window_path)\n",
    "\n",
    "  def loader(self, path):\n",
    "    in_file = open(path, 'rb')\n",
    "    image = self.jpeg_reader.decode(in_file.read(), 0)\n",
    "    image = transform(**{\"image\": image})\n",
    "    test = image['image']\n",
    "    image = torch.from_numpy(image['image'])\n",
    "    return image, test\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_1, test_1 = self.loader(self.window_paths[index][0])\n",
    "    img_2, test_2 = self.loader(self.window_paths[index][1])\n",
    "    img_3, test_3 = self.loader(self.window_paths[index][2])\n",
    "\n",
    "    test = np.concatenate((test_1, test_2, test_3),axis=2)\n",
    "    test = np.rollaxis(test, 2, 0)\n",
    "    test = torch.from_numpy(test)\n",
    "    img_window = test\n",
    "\n",
    "    centre_img = cv.imread(self.window_paths[index][1])\n",
    "    centre_img = cv.resize(centre_img, (TN_width, TN_height))\n",
    "    centre_img.astype(np.float32)\n",
    "\n",
    "    return img_window, centre_img\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.window_paths)\n",
    "\n",
    "# Extracts all the frames from a video and saves them\n",
    "def preprocess(video_path):\n",
    "  cap = cv.VideoCapture(video_path)\n",
    "  ret, frame = cap.read()\n",
    "  count=0\n",
    "  while(ret):\n",
    "    frame = cv.resize(frame, (1280,720), interpolation= cv.INTER_LINEAR)\n",
    "    cv.imwrite(f\"tmp/{count:04d}.jpg\", frame)\n",
    "    ret, frame = cap.read()\n",
    "    count += 1\n",
    "    if count %200 == 0:\n",
    "      print(f\"Frame {count}\")\n",
    "  cap.release\n",
    "\n",
    "def predict(video_path, preprocessing=True):\n",
    "  if preprocessing:\n",
    "    print(\"Preprocessing\")\n",
    "    preprocess(video_path)\n",
    "  print(\"Loading demo dataset\")\n",
    "  demo_loader = DataLoader(DemoDataset(), batch_size=1,shuffle=False,num_workers=num_workers,pin_memory=True,drop_last=True)\n",
    "  colors = [(i, i, i) for i in range(0, 256)]\n",
    "\n",
    "  print(\"Making Predictions\")\n",
    "  preds = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    with tqdm(demo_loader, unit=\"batch\") as depoch:\n",
    "      for data_batch in depoch:\n",
    "        depoch.set_description(f\"Demo\")\n",
    "        # Read in demo batch\n",
    "        img_window, centre_img = data_batch\n",
    "        window_batch = torch.as_tensor(img_window,dtype=torch.float32).to(device)\n",
    "        window_batch=window_batch.view(-1,9,360,640).to(device)\n",
    "\n",
    "        # Forward step\n",
    "        output = model(window_batch)\n",
    "        output_re = np.array(output.detach().tolist())\n",
    "        output_re = output_re.reshape((TN_height, TN_width, 256)).argmax(axis=2)\n",
    "        output_re = output_re.astype(np.uint8)  \n",
    "\n",
    "        heatmap  = cv.resize(output_re, (1280,720))\n",
    "        ret,heatmap = cv.threshold(heatmap,127,255,cv.THRESH_BINARY)\n",
    "        circles = cv.HoughCircles(heatmap, cv.HOUGH_GRADIENT,dp=1,minDist=1,param1=50,param2=2,minRadius=2,maxRadius=7)\n",
    "\n",
    "        if circles is not None and len(circles) == 1:\n",
    "          x = int(circles[0][0][0])\n",
    "          y = int(circles[0][0][1])\n",
    "          preds.append([x, y])\n",
    "          tqdm.write(f\"{x}, {y}\")\n",
    "        else:\n",
    "          preds.append([-1, -1])\n",
    "          tqdm.write(f\"{-1}, {-1}\")\n",
    "    out = np.array(preds)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrackNet(inchannel=9).to(device)\n",
    "savePath = f\"{savePath_base}/New_loader/TrackNet_15.pth\"\n",
    "checkpoint = torch.load(savePath)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "preds = predict(\"./Videos/test.mp4\", preprocessing=False)\n",
    "np.savetxt('preds.txt', preds, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up detections and predict events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.loadtxt('preds.txt', dtype=\"int\")\n",
    "x, y = preds[:,0], preds[:,1]\n",
    "\n",
    "i = 0\n",
    "while x[i] == -1:\n",
    "  i += 1\n",
    "x[:i] = x[i]\n",
    "\n",
    "i = 0\n",
    "while y[i] == -1:\n",
    "  i += 1\n",
    "y[:i] = y[i]\n",
    "\n",
    "plt.clf()\n",
    "plt.title('X')\n",
    "plt.plot(range(0,x.shape[0]), x)\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.title('Y')\n",
    "plt.plot(range(0,y.shape[0]), y)\n",
    "plt.show()\n",
    "\n",
    "x_detections, x_minima, x_maxima = refine_detections(x, repeats=3)\n",
    "y_detections, y_minima, y_maxima = refine_detections(y, repeats=3)\n",
    "\n",
    "x_extrema = [*x_minima, *x_maxima]\n",
    "x_extrema.sort()\n",
    "x_extrema = clean_extrema(x_extrema)\n",
    "\n",
    "y_maxima.sort()\n",
    "y_maxima = clean_extrema(y_maxima)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_detections, label=\"Smoothed\")\n",
    "plt.plot(x, label=\"Base\")\n",
    "for extreme in x_extrema:\n",
    " plt.axvline(x = extreme, color = 'b',)\n",
    "plt.title('X')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(y_detections, label=\"Smoothed\")\n",
    "plt.plot(y, label=\"Base\")\n",
    "for max in y_maxima:\n",
    " plt.axvline(x = max, color = 'b',)\n",
    "plt.title('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = './Videos/corner_rally.mp4'\n",
    "output_video_path = './Results/corner_events_50.mp4'\n",
    "\n",
    "cap = cv.VideoCapture(input_video_path)\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "output_width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "output_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter(output_video_path,fourcc, fps, (output_width,output_height))\n",
    "\n",
    "frame_no = 0\n",
    "while(cap.isOpened()):\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "    cv.circle(frame,(int(x_detections[frame_no]),int(y_detections[frame_no])), 8, (0, 0, 255), 2)\n",
    "    cv.circle(frame,(int(x[frame_no]),int(y[frame_no])), 8, (0, 255, 0), 2)\n",
    "    if frame_no in x_extrema:\n",
    "      cv.putText(frame, f\"Hit - frame {frame_no}\", (50, 100), cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 0, 0), 2)\n",
    "    if frame_no in y_maxima:\n",
    "      cv.putText(frame, f\"Bounce - frame {frame_no}\", (50, 150), cv.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "    frame_no += 1\n",
    "    out.write(frame)\n",
    "\n",
    "    if (frame_no%50) == 0:\n",
    "      print(frame_no)\n",
    "\n",
    "  # Break the loop\n",
    "  else:\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pre, gt, name):\n",
    "  rmse = np.sqrt(np.mean((gt[:, :2]-pre)**2))\n",
    "  mae_x = np.mean(np.abs((gt[:, 0]-pre[:, 0])))\n",
    "  mae_y = np.mean(np.abs((gt[:, 1]-pre[:, 1])))\n",
    "  medae_x = np.median(np.abs((gt[:, 0]-pre[:, 0])))\n",
    "  medae_y = np.median(np.abs((gt[:, 1]-pre[:, 1])))\n",
    "\n",
    "  print(f\"{name}:\")\n",
    "  print(f\"\\tRMSE : {rmse:.3f}\")\n",
    "  print(f\"\\tMAE X : {mae_x:.3f}\\t MAE Y : {mae_y:.3f}\")\n",
    "  print(f\"\\tMedAE X : {medae_x:.3f}\\t MAE Y : {medae_y:.3f}\")\n",
    "\n",
    "def get_dists(pre, gt):\n",
    "  gt = np.array(gt, dtype=np.float64)\n",
    "  dists = np.linalg.norm(gt[:, :2] - pre, axis=1)\n",
    "  dists[dists == 0] = 0.001\n",
    "  log_dists = np.log10(dists)\n",
    "  return log_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localisation Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "data = np.loadtxt(\"./Results/01.txt\")\n",
    "for i in range(2, 31):\n",
    "  data = np.append(data, np.loadtxt(f\"./Results/{i:02}.txt\"), axis=0)\n",
    "print(data.shape)\n",
    "\n",
    "# Load groundtruth\n",
    "label = pd.read_csv(\"./Dataset/test/01/Clip6/Label.csv\")\n",
    "label = label.fillna(-1)\n",
    "label = label.to_numpy()\n",
    "label = label[:, 2:]\n",
    "gt = label\n",
    "\n",
    "base_dir = \"./Dataset/test\"\n",
    "games = os.listdir(base_dir)\n",
    "games.remove(\"groundtruth\")\n",
    "games.remove(\"01\")\n",
    "games.sort()\n",
    "\n",
    "for game in games:\n",
    "  clips = os.listdir(f\"{base_dir}/{game}\")\n",
    "  for clip in clips:\n",
    "    label_path = f\"{base_dir}/{game}/{clip}/Label.csv\"\n",
    "    label = pd.read_csv(label_path)\n",
    "    label = label.fillna(-1)\n",
    "    label = label.to_numpy()\n",
    "    label = label[:, 2:]\n",
    "    gt = np.append(gt, label, axis=0)\n",
    "print(gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictions and groundtruth into court types\n",
    "hard_pre, hard_gt = data[:6000], gt[:6000]\n",
    "grass_pre, grass_gt = data[6000:7500], gt[6000:7500]\n",
    "clay_pre, clay_gt = data[7500:], gt[7500:]\n",
    "\n",
    "metrics(data, gt, \"All Courts\")\n",
    "metrics(hard_pre, hard_gt, \"Hard Court\")\n",
    "metrics(grass_pre, grass_gt, \"Grass Court\")\n",
    "metrics(clay_pre, clay_gt, \"Clay Court\")\n",
    "\n",
    "all_dists_log = get_dists(data, gt)\n",
    "hard_dists_log = get_dists(hard_pre, hard_gt)\n",
    "grass_dists_log = get_dists(grass_pre, grass_gt)\n",
    "clay_dists_log = get_dists(clay_pre, clay_gt)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(dpi=300)\n",
    "plt.title(f'Differences in Predicted Location (TrackNet)')\n",
    "b, bins, p = plt.hist(all_dists_log, bins=np.linspace(0, 3, 30), alpha=0.7, label=\"All Courts\")\n",
    "vals, bins, patches = plt.hist([hard_dists_log, grass_dists_log, clay_dists_log], bins=np.linspace(0, 3, 30), label=[\"Hard Courts\", \"Grass Courts\", \"Clay Courts\"])\n",
    "all_samples = np.sum(b)\n",
    "hard_samples = np.sum(vals[0])\n",
    "grass_samples = np.sum(vals[1])\n",
    "clay_samples = np.sum(vals[2])\n",
    "\n",
    "# Normalise the histogram\n",
    "for i in range(vals.shape[1]):\n",
    "  # Change all court values\n",
    "  p[i].set_height(p[i].get_height()/all_samples)\n",
    "  b[i] /= all_samples\n",
    "\n",
    "  patches[0][i].set_height(patches[0][i].get_height()/hard_samples)\n",
    "  vals[0][i] /= hard_samples\n",
    "\n",
    "  patches[1][i].set_height(patches[1][i].get_height()/grass_samples)\n",
    "  vals[1][i] /= grass_samples\n",
    "\n",
    "  patches[2][i].set_height(patches[2][i].get_height()/clay_samples)\n",
    "  vals[2][i] /= clay_samples\n",
    "\n",
    "plt.legend()\n",
    "labels = ['1', '10', '100', '1000']\n",
    "plt.ylim([0, 0.3])\n",
    "plt.xticks(np.arange(0, 4, 1), labels)\n",
    "plt.xlabel('Distance (pixels)')\n",
    "plt.ylabel('Ratio')\n",
    "plt.savefig(f\"./Results/base_court_diffs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrackNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "games = os.listdir(base_dir)\n",
    "games.remove(\"groundtruth\")\n",
    "games.sort()\n",
    "data_refined = []\n",
    "\n",
    "preds = np.loadtxt(f\"./Results/01.txt\")\n",
    "x, y = preds[:,0], preds[:,1]\n",
    "\n",
    "i = 0\n",
    "while x[i] == -1:\n",
    "  i += 1\n",
    "x[:i] = x[i]\n",
    "\n",
    "i = 0\n",
    "while y[i] == -1:\n",
    "  i += 1\n",
    "y[:i] = y[i]\n",
    "\n",
    "_, _, _, x_unfiltered = refine_detections(x, repeats=3)\n",
    "_, _, _, y_unfiltered = refine_detections(y, repeats=3)\n",
    "x_unfiltered.shape = (300,1)\n",
    "y_unfiltered.shape = (300,1)\n",
    "data_refined = np.hstack((x_unfiltered, y_unfiltered))\n",
    "data_refined = data_refined.astype(int)\n",
    "\n",
    "for game in range(2, 31):\n",
    "  # Get predictions\n",
    "  preds = np.loadtxt(f\"{game:02}.txt\")\n",
    "  x, y = preds[:,0], preds[:,1]\n",
    "\n",
    "  i = 0\n",
    "  while x[i] == -1:\n",
    "    i += 1\n",
    "  x[:i] = x[i]\n",
    "\n",
    "  i = 0\n",
    "  while y[i] == -1:\n",
    "    i += 1\n",
    "  y[:i] = y[i]\n",
    "  \n",
    "  _, _, _, x_unfiltered = refine_detections(x, repeats=3)\n",
    "  _, _, _, y_unfiltered = refine_detections(y, repeats=3)\n",
    "  x_unfiltered.shape = (300,1)\n",
    "  y_unfiltered.shape = (300,1)\n",
    "  xy = np.hstack((x_unfiltered, y_unfiltered))\n",
    "  xy = xy.astype(int)\n",
    "  data_refined = np.append(data_refined, xy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictions and groundtruth into court types\n",
    "hard_pre_ref, hard_gt = data_refined[:6000], gt[:6000]\n",
    "grass_pre_ref, grass_gt = data_refined[6000:7500], gt[6000:7500]\n",
    "clay_pre_ref, clay_gt = data_refined[7500:], gt[7500:]\n",
    "\n",
    "metrics(data_refined, gt, \"All Courts\")\n",
    "metrics(hard_pre_ref, hard_gt, \"Hard Court\")\n",
    "metrics(grass_pre_ref, grass_gt, \"Grass Court\")\n",
    "metrics(clay_pre_ref, clay_gt, \"Clay Court\")\n",
    "\n",
    "all_dists_log = get_dists(data_refined, gt)\n",
    "hard_dists_log = get_dists(hard_pre_ref, hard_gt)\n",
    "grass_dists_log = get_dists(grass_pre_ref, grass_gt)\n",
    "clay_dists_log = get_dists(clay_pre_ref, clay_gt)\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(dpi=300)\n",
    "plt.title(f'Differences in Predicted Location (TrackNet*)')\n",
    "b, bins, p = plt.hist(all_dists_log, bins=np.linspace(0, 3, 30), alpha=0.7, label=\"All Courts\")\n",
    "vals, bins, patches = plt.hist([hard_dists_log, grass_dists_log, clay_dists_log], bins=np.linspace(0, 3, 30), label=[\"Hard Courts\", \"Grass Courts\", \"Clay Courts\"])\n",
    "all_samples = np.sum(b)\n",
    "hard_samples = np.sum(vals[0])\n",
    "grass_samples = np.sum(vals[1])\n",
    "clay_samples = np.sum(vals[2])\n",
    "\n",
    "# Normalise the histogram\n",
    "for i in range(vals.shape[1]):\n",
    "  # Change all court values\n",
    "  p[i].set_height(p[i].get_height()/all_samples)\n",
    "  b[i] /= all_samples\n",
    "\n",
    "  patches[0][i].set_height(patches[0][i].get_height()/hard_samples)\n",
    "  vals[0][i] /= hard_samples\n",
    "\n",
    "  patches[1][i].set_height(patches[1][i].get_height()/grass_samples)\n",
    "  vals[1][i] /= grass_samples\n",
    "\n",
    "  patches[2][i].set_height(patches[2][i].get_height()/clay_samples)\n",
    "  vals[2][i] /= clay_samples\n",
    "\n",
    "plt.legend()\n",
    "labels = ['1', '10', '100', '1000']\n",
    "plt.ylim([0, 0.3])\n",
    "plt.xticks(np.arange(0, 4, 1), labels)\n",
    "plt.xlabel('Distance (pixels)')\n",
    "plt.ylabel('Ratio')\n",
    "plt.savefig(f\"./Results/processed_court_diffs.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./Dataset/test\"\n",
    "games = os.listdir(base_dir)\n",
    "games.remove(\"groundtruth\")\n",
    "games.sort()\n",
    "\n",
    "eve = 0\n",
    "pre_3 = 0\n",
    "pre_5 = 0\n",
    "pre_10 = 0\n",
    "pre_15 = 0\n",
    "pre_30 = 0\n",
    "\n",
    "for game in range(1, 31):\n",
    "  # Get predictions\n",
    "  preds = np.loadtxt(f\"./Results/{game:02}.txt\")\n",
    "  x = preds[:,0]\n",
    "  y = preds[:,1]\n",
    "\n",
    "  i = 0\n",
    "  while x[i] == -1:\n",
    "    i += 1\n",
    "  x[:i] = x[i]\n",
    "\n",
    "  i = 0\n",
    "  while y[i] == -1:\n",
    "    i += 1\n",
    "  y[:i] = y[i]\n",
    "\n",
    "  # Load groundtruth\n",
    "  clips = os.listdir(f\"{base_dir}/{game:02}\")\n",
    "  gt = None\n",
    "  for clip in clips:\n",
    "    label_path = f\"{base_dir}/{game:02}/{clip}/Label.csv\"\n",
    "    label = pd.read_csv(label_path)\n",
    "    label = label.fillna(0)\n",
    "    label = label.to_numpy()\n",
    "    label = label[:, 4:]\n",
    "    if gt is not None:\n",
    "      gt = np.append(gt, label, axis=0)\n",
    "    else:\n",
    "      gt = label\n",
    "  \n",
    "  x_detections, x_minima, x_maxima, _ = refine_detections(x, repeats=3)\n",
    "  y_detections, y_minima, y_maxima, _ = refine_detections(y, repeats=3)\n",
    "\n",
    "  x_extrema = [*x_minima, *x_maxima]\n",
    "  x_extrema.sort()\n",
    "  x_extrema = clean_extrema(x_extrema)\n",
    "\n",
    "  y_maxima = [*y_maxima]\n",
    "  y_maxima.sort()\n",
    "  y_maxima = clean_extrema(y_maxima)\n",
    "\n",
    "  hit_ids = np.where(np.all(gt==[1.],axis=1))[0]\n",
    "  bounce_ids = np.where(np.all(gt==[2.],axis=1))[0]\n",
    "  event_num = 0\n",
    "  pre_num = 0\n",
    "\n",
    "  for id in hit_ids:\n",
    "    eve += 1\n",
    "    for pre in x_extrema:\n",
    "      if id-3 <= pre <= id+3:\n",
    "        pre_3 += 1\n",
    "      if id-5 <= pre <= id+5:\n",
    "        pre_5 += 1\n",
    "      if id-10 <= pre <= id+10:\n",
    "        pre_10 += 1\n",
    "      if id-15 <= pre <= id+15:\n",
    "        pre_15 += 1\n",
    "      if id-30 <= pre <= id+30:\n",
    "        pre_30 += 1\n",
    "\n",
    "  for id in bounce_ids:\n",
    "    eve += 1\n",
    "    for pre in y_maxima:\n",
    "      if id-3 <= pre <= id+3:\n",
    "        pre_3 += 1\n",
    "      if id-5 <= pre <= id+5:\n",
    "        pre_5 += 1\n",
    "      if id-10 <= pre <= id+10:\n",
    "        pre_10 += 1\n",
    "      if id-15 <= pre <= id+15:\n",
    "        pre_15 += 1\n",
    "      if id-30 <= pre <= id+30:\n",
    "        pre_30 += 1\n",
    "\n",
    "print(f\"3 frame window : {pre_3}/{eve} = {pre_3/eve:.3f}\")\n",
    "print(f\"5 frame window : {pre_5}/{eve} = {pre_5/eve:.3f}\")\n",
    "print(f\"10 frame window : {pre_10}/{eve} = {pre_10/eve:.3f}\")\n",
    "print(f\"15 frame window : {pre_15}/{eve} = {pre_15/eve:.3f}\")\n",
    "print(f\"30 frame window : {pre_30}/{eve} = {pre_30/eve:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ttn-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "977ae9768b98c0a6351747d91b3b0f777616684af223aba46050bfee78a134e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
